

'''

DOne : [0.1 to 0.9], [0.01, 0.09]

export CUDA_VISIBLE_DEVICES=0
cd vaeBench/betaVAE
conda activate vaeBench
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.1 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.2 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.3 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.4 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.5 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.6 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.7 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.8 --seedVal 0
python trainBetaVAE.py --latentDimesion 6 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.9 --seedVal 0


export CUDA_VISIBLE_DEVICES=0
cd vaeBench/betaVAE
conda activate vaeBench
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.1 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.2 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.3 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.4 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.5 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.6 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.7 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.8 --seedVal 0
python trainBetaVAE.py --latentDimesion 8 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.9 --seedVal 0


export CUDA_VISIBLE_DEVICES=0
cd vaeBench/betaVAE
conda activate vaeBench
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.1 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.2 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.3 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.4 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.5 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.6 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.7 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.8 --seedVal 0
python trainBetaVAE.py --latentDimesion 10 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.9 --seedVal 0


export CUDA_VISIBLE_DEVICES=0
cd vaeBench/betaVAE
conda activate vaeBench
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.1 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.2 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.3 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.4 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.5 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.6 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.7 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.8 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.9 --seedVal 0



#############################################################################################################


export CUDA_VISIBLE_DEVICES=1
cd vaeBench/betaVAE
conda activate vaeBench
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 1.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 2.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 3.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 4.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 5.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 6.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 7.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 8.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 9.0 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 10.0 --seedVal 0

python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.01 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.02 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.03 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.04 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.05 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.06 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.07 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.08 --seedVal 0
python trainBetaVAE.py --latentDimesion 12 --learningRate 1e-4 --numEpochs 100 --dataset MNIST --betaValue 0.09 --seedVal 0


'''


import torch
import torchvision.datasets as datasets





import numpy as np
import random
import os


import argparse

parser = argparse.ArgumentParser(description='disentanglement experiments')
parser.add_argument('--latentDimesion', type=int, default=2, help='Latent dimension')
parser.add_argument('--learningRate', type=float, default=1e-4, help='learningRate ')
parser.add_argument('--numEpochs', type=int, default=100, help='numEpochs ')
parser.add_argument('--dataset', type=str, default="MNIST", help='dataset ')
parser.add_argument('--betaValue', type=float, default=2.0, help='learningRate ')
parser.add_argument('--seedVal', type=int, default=42, help='learningRate ')

args = parser.parse_args()

latentDimesion = args.latentDimesion
learningRate = args.learningRate
numEpochs = args.numEpochs
dataset = args.dataset
betaValue = args.betaValue
seedVal = args.seedVal


#seedVal = 0

def set_seed(seed=seedVal):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # for multi-GPU setups

    # Ensure deterministic behavior
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    # For reproducibility of data loaders
    os.environ["PYTHONHASHSEED"] = str(seed)

set_seed(seedVal)




import inspect


device = "cuda" if torch.cuda.is_available() else "cpu"


mnist_trainset = datasets.MNIST(root='../../data', train=True, download=True, transform=None)

train_dataset = mnist_trainset.data[:-10000].reshape(-1, 1, 28, 28) / 255.
eval_dataset = mnist_trainset.data[-10000:].reshape(-1, 1, 28, 28) / 255.



from pythae.models import BetaVAE, BetaVAEConfig
from pythae.trainers import BaseTrainerConfig
from pythae.pipelines.training import TrainingPipeline
from pythae.models.nn.benchmarks.mnist import Encoder_ResNet_VAE_MNIST, Decoder_ResNet_AE_MNIST







config = BaseTrainerConfig(
    output_dir='my_model',
    learning_rate=learningRate,
    per_device_train_batch_size=64,
    per_device_eval_batch_size=64,
    num_epochs=numEpochs, # Change this to train the model a bit more
)


model_config = BetaVAEConfig(
    input_dim=(1, 28, 28),
    latent_dim=latentDimesion,
    beta=betaValue

)

model = BetaVAE(
    model_config=model_config,
    encoder=Encoder_ResNet_VAE_MNIST(model_config), 
    decoder=Decoder_ResNet_AE_MNIST(model_config) 
)


pipeline = TrainingPipeline(
    training_config=config,
    model=model
)

pipeline(
    train_data=train_dataset,
    eval_data=eval_dataset
)

print("type(pipeline) file:", inspect.getsourcefile(type(pipeline)))


import os
from pythae.models import AutoModel



torch.save(model.state_dict(), 'modelSaves/AE_latentDimesion_'+str(latentDimesion)+'_learningRate_'+str(learningRate)+'_numEpochs_'+str(numEpochs)+'_'+dataset+'_betaValue_'+str(betaValue)+'_seed_val_'+str(seedVal)+'_.pth')


trained_model = BetaVAE(
    model_config=model_config,
    encoder=Encoder_ResNet_VAE_MNIST(model_config), 
    decoder=Decoder_ResNet_AE_MNIST(model_config) 
)

trained_model.load_state_dict(torch.load('modelSaves/AE_latentDimesion_'+str(latentDimesion)+'_learningRate_'+str(learningRate)+'_numEpochs_'+str(numEpochs)+'_'+dataset+'_betaValue_'+str(betaValue)+'_seed_val_'+str(seedVal)+'_.pth', map_location=device))


#last_training = sorted(os.listdir('my_model'))[-1]
#trained_model = AutoModel.load_from_folder(os.path.join('my_model', last_training, 'final_model'))



from pythae.samplers import NormalSampler


# create normal sampler
normal_samper = NormalSampler(
    model=trained_model
)


# sample
gen_data = normal_samper.sample(
    num_samples=25
)


import matplotlib.pyplot as plt


# show results with normal sampler
fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))

for i in range(5):
    for j in range(5):
        axes[i][j].imshow(gen_data[i*5 +j].cpu().squeeze(0), cmap='gray')
        axes[i][j].axis('off')
plt.tight_layout(pad=0.)
plt.tight_layout(pad=0.)
plt.savefig("pictures/generatedSamples.png", dpi=300, bbox_inches="tight")
plt.show()


from pythae.samplers import GaussianMixtureSampler, GaussianMixtureSamplerConfig



# set up gmm sampler config
gmm_sampler_config = GaussianMixtureSamplerConfig(
    n_components=10
)

# create gmm sampler
gmm_sampler = GaussianMixtureSampler(
    sampler_config=gmm_sampler_config,
    model=trained_model
)

# fit the sampler
gmm_sampler.fit(train_dataset)



# sample
gen_data = gmm_sampler.sample(
    num_samples=25
)



# show results with gmm sampler
fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))

for i in range(5):
    for j in range(5):
        axes[i][j].imshow(gen_data[i*5 +j].cpu().squeeze(0), cmap='gray')
        axes[i][j].axis('off')
plt.tight_layout(pad=0.)
plt.savefig("pictures/gmmSamplerGeneratedSamples.png", dpi=300, bbox_inches="tight")
plt.show()

reconstructions = trained_model.reconstruct(eval_dataset[:25].to(device)).detach().cpu()



# show reconstructions
fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))

for i in range(5):
    for j in range(5):
        axes[i][j].imshow(reconstructions[i*5 + j].cpu().squeeze(0), cmap='gray')
        axes[i][j].axis('off')
plt.tight_layout(pad=0.)
plt.savefig("pictures/evalDatasetReconstructions.png", dpi=300, bbox_inches="tight")
plt.show()


# show the true data
fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))

for i in range(5):
    for j in range(5):
        axes[i][j].imshow(eval_dataset[i*5 +j].cpu().squeeze(0), cmap='gray')
        axes[i][j].axis('off')
plt.tight_layout(pad=0.)
plt.savefig("pictures/evalDataset.png", dpi=300, bbox_inches="tight")
plt.show()

interpolations = trained_model.interpolate(eval_dataset[:5].to(device), eval_dataset[5:10].to(device), granularity=10).detach().cpu()


# show interpolations
fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(10, 5))

for i in range(5):
    for j in range(10):
        axes[i][j].imshow(interpolations[i, j].cpu().squeeze(0), cmap='gray')
        axes[i][j].axis('off')
plt.tight_layout(pad=0.)
plt.savefig("pictures/interpolations.png", dpi=300, bbox_inches="tight")
plt.show()

